{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9370da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e312d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data\n",
    "X = np.random.randint(0, 10, 30).reshape(6, 5)\n",
    "\n",
    "y = np.random.randint(0, 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29eb4754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f4f57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y,k):\n",
    "    y_hot = np.zeros((len(y),k)) # Creating the zero matrix\n",
    "    y_hot[np.arange(len(y)), y] = 1\n",
    "    return y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "780946c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58299dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    # z = w . X\n",
    "    y_hat = np.exp(z - np.max(z))\n",
    "    for i in range(len(z)):\n",
    "        y_hat[i] /= np.sum(y_hat[i])\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb0384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba34a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "w =np.random.randint(0,9,60).reshape(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "305721e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 94, 130,  59,  74,  77],\n",
       "       [ 92, 142,  88,  66,  62],\n",
       "       [ 94, 124,  82,  62,  55],\n",
       "       [101, 133,  73,  66,  74],\n",
       "       [ 82, 103,  70,  66,  66],\n",
       "       [116, 148, 106,  90,  62],\n",
       "       [ 30,  63,  48,  54,  56],\n",
       "       [ 75, 107,  52,  80,  67],\n",
       "       [100, 122,  50,  78,  76],\n",
       "       [ 57,  70,  36,  38,  29]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.dot(w,X)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c50b3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.319523e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.462486e-31</td>\n",
       "      <td>4.780893e-25</td>\n",
       "      <td>9.602680e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.928750e-22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.532629e-24</td>\n",
       "      <td>9.854155e-34</td>\n",
       "      <td>1.804851e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.357623e-14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.749522e-19</td>\n",
       "      <td>1.185065e-27</td>\n",
       "      <td>1.080639e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.266417e-14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.756511e-27</td>\n",
       "      <td>7.984904e-30</td>\n",
       "      <td>2.380266e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.582560e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.658886e-15</td>\n",
       "      <td>8.533048e-17</td>\n",
       "      <td>8.533048e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.266417e-14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.749522e-19</td>\n",
       "      <td>6.470235e-26</td>\n",
       "      <td>4.473779e-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.654066e-15</td>\n",
       "      <td>0.998965</td>\n",
       "      <td>3.055859e-07</td>\n",
       "      <td>1.232821e-04</td>\n",
       "      <td>9.109386e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.266417e-14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.299581e-24</td>\n",
       "      <td>1.879529e-12</td>\n",
       "      <td>4.248354e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.789468e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.380186e-32</td>\n",
       "      <td>7.781132e-20</td>\n",
       "      <td>1.053062e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.260324e-06</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.713905e-15</td>\n",
       "      <td>1.266414e-14</td>\n",
       "      <td>1.562879e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1             2             3             4\n",
       "0  2.319523e-16  1.000000  1.462486e-31  4.780893e-25  9.602680e-24\n",
       "1  1.928750e-22  1.000000  3.532629e-24  9.854155e-34  1.804851e-35\n",
       "2  9.357623e-14  1.000000  5.749522e-19  1.185065e-27  1.080639e-30\n",
       "3  1.266417e-14  1.000000  8.756511e-27  7.984904e-30  2.380266e-26\n",
       "4  7.582560e-10  1.000000  4.658886e-15  8.533048e-17  8.533048e-17\n",
       "5  1.266417e-14  1.000000  5.749522e-19  6.470235e-26  4.473779e-38\n",
       "6  4.654066e-15  0.998965  3.055859e-07  1.232821e-04  9.109386e-04\n",
       "7  1.266417e-14  1.000000  1.299581e-24  1.879529e-12  4.248354e-18\n",
       "8  2.789468e-10  1.000000  5.380186e-32  7.781132e-20  1.053062e-20\n",
       "9  2.260324e-06  0.999998  1.713905e-15  1.266414e-14  1.562879e-18"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = softmax(z)\n",
    "pd.DataFrame(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57dbe7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = np.nan_to_num(B)\n",
    "#pd.DataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c78ee9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16b3e782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "90ea03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_fit(X, y, lr, k, epochs):\n",
    "    n, m = X.shape\n",
    "    w = np.random.random((m, k))\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        z  = X @ w\n",
    "        y_hat = softmax(z)\n",
    "        y_hot = one_hot(y, k)\n",
    "        w_grad = (1/n)*np.dot(X.T, (y_hat - y_hot))\n",
    "        w = w - lr*w_grad\n",
    "        loss = - np.mean(np.log(y_hat[np.arange(len(y)), y]))\n",
    "        print(loss)\n",
    "        losses.append(loss)\n",
    "                \n",
    "    return w, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "164db229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45640193,  0.41439964,  0.95711628,  0.17336215,  0.37843948,\n",
       "         0.79843923],\n",
       "       [ 0.19931854,  0.67561571,  0.34553143,  0.84036339,  0.52463881,\n",
       "         0.82318835],\n",
       "       [ 0.23987691,  0.90907458,  0.19172962,  0.43703151,  0.08258351,\n",
       "         0.53051672],\n",
       "       [ 0.8420249 ,  0.38602562,  0.18760448,  0.65329403,  0.85769916,\n",
       "         0.73452827],\n",
       "       [ 0.91251635,  0.73184146,  0.50525887,  0.81333924,  0.86253313,\n",
       "        -0.02400039]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c3553f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working\n",
    "def logistic_fit_s(X, y,k):\n",
    "    n, m = X.shape\n",
    "    w = np.random.random((m, k))\n",
    "    #loss = []\n",
    "    z  = X @ w\n",
    "    y_hat = softmax(z)\n",
    "    y_hot = one_hot(y, k)\n",
    "    w_grad = (1/n)*np.dot(w, (y_hat - y_hot))\n",
    "    #w = w - lr*w_grad\n",
    "    loss = - np.mean(np.log(y_hat[np.arange(len(y)), y]))\n",
    "    print(loss)\n",
    "    snd_order = minimize(w_grad,w_hat, method='BFGS')\n",
    "        \n",
    "    return snd_order\n",
    "#Not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eaad51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_fit_s2(X, y, lr, k, epochs):\n",
    "    n, m = X.shape\n",
    "    w = np.random.random((m, k))\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        z  = X @ w\n",
    "        y_hat = softmax(z)\n",
    "        y_hot = one_hot(y, k)\n",
    "        w_grad = (1/n)*np.dot(X.T, (y_hat - y_hot))\n",
    "        w = w - lr*w_grad\n",
    "        loss = - np.mean(np.log(y_hat[np.arange(len(y)), y]))\n",
    "        print(loss)\n",
    "        losses.append(loss)\n",
    "        snd_order = minimize(losses,w_grad, method='BFGS')\n",
    "                \n",
    "    return w, losses, snd_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70aee536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.445305396787268\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10052/2977882596.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogistic_fit_s2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10052/1426132276.py\u001b[0m in \u001b[0;36mlogistic_fit_s2\u001b[1;34m(X, y, lr, k, epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msnd_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'BFGS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnd_order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[0mmaxiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m     sf = _prepare_scalar_function(fun, x0, jac, args=args, epsilon=eps,\n\u001b[0m\u001b[0;32m   1202\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[0;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m# Gradient evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "minimize(w_grad,losses, method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0e878b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_hat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10052/2624577433.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_hot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_hat' is not defined"
     ]
    }
   ],
   "source": [
    "(1/n)*np.dot(X.T, (y_hat - y_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eb1422ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.84784219,  0.00489429, -0.99941085, -1.49788062, -0.59197271,\n",
       "         2.23652771],\n",
       "       [ 1.74789264,  0.02972774, -1.49808058, -2.14477624, -0.81931699,\n",
       "         2.68455343],\n",
       "       [ 0.52308565,  0.01781197, -0.99871652, -2.15609728,  0.29928156,\n",
       "         2.31463461],\n",
       "       [ 0.56118023,  0.03251785, -0.99775895, -0.64576067, -0.07770862,\n",
       "         1.12753016],\n",
       "       [ 1.14060407,  0.02832357, -1.3315865 , -0.64611782, -0.21643113,\n",
       "         1.02520781]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=6\n",
    "n, m = X.shape\n",
    "w = np.random.random((m, k))\n",
    "z  = X @ w\n",
    "y_hat = softmax(z)\n",
    "y_hot = one_hot(y, k)\n",
    "grad=(1/n)*np.dot(X.T, (y_hat - y_hot))\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fb7cf458",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = n, m = X.shape\n",
    "k=6\n",
    "w = np.random.random((m, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7b1565c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, y_hot, w):\n",
    "    Z = - X @ w\n",
    "    N = X.shape[0]\n",
    "    loss = 1/N * (np.trace(X @ w @ y_hot.T) + np.sum(np.log(np.sum(np.exp(Z), axis=1))))\n",
    "    return loss\n",
    "\n",
    "def gradient(X, y_hot, W, m):\n",
    "    Z = - X @ W\n",
    "    P = softmax(Z)\n",
    "    n = X.shape[0]\n",
    "    gd = 1/n * (X.T @ (y_hot - P)) + 2 * m * W\n",
    "    return gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7925941f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7232720229726284"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(X,y_hot,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "89fa13c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.63563106, 11.46398026,  3.53753016,  6.9417849 ,  4.16849622,\n",
       "        -0.04000163],\n",
       "       [ 9.95800899,  0.82549944,  3.71452638, 11.67339855, 11.6678761 ,\n",
       "         1.15221519],\n",
       "       [ 9.20279947,  8.81466919,  1.84136521,  4.9094255 ,  6.6613211 ,\n",
       "        10.96706454],\n",
       "       [ 6.14489268,  7.18302396, 12.55628778,  2.03265566, 10.03943246,\n",
       "         1.91575725],\n",
       "       [ 7.72660851,  4.12290396,  4.48368634,  5.86945487,  0.80256951,\n",
       "         1.50834937]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(X,y_hot,w,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1269139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_fit_s2(X, y, lr, k, epochs):\n",
    "    n, m = X.shape\n",
    "    w = np.random.random((m, k))\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        z  = X @ w\n",
    "        y_hat = softmax(z)\n",
    "        y_hot = one_hot(y, k)\n",
    "        w_grad = (1/n)*np.dot(X.T, (y_hat - y_hot))\n",
    "        w = w - lr*w_grad\n",
    "        loss = - np.mean(np.log(y_hat[np.arange(len(y)), y]))\n",
    "        #print(loss)\n",
    "        losses.append(loss)\n",
    "        snd_order = minimize(losses,w_grad,gradient(X,y_hot,w,6), method='BFGS')\n",
    "                \n",
    "    return w, losses, snd_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cbf05a53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10052/983289098.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogistic_fit_s2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10052/2996227065.py\u001b[0m in \u001b[0;36mlogistic_fit_s2\u001b[1;34m(X, y, lr, k, epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#print(loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msnd_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_hot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'BFGS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnd_order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[0mmaxiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m     sf = _prepare_scalar_function(fun, x0, jac, args=args, epsilon=eps,\n\u001b[0m\u001b[0;32m   1202\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[0;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m# Gradient evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "logistic_fit_s2(X,y,0.01,6,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e794da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34ea0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w):\n",
    "    z = X @ w\n",
    "    print(z)\n",
    "    y_hat = softmax(z)\n",
    "    print(y_hat)\n",
    "    return np.argmax(y_hat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00ce8aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3ac6555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.644964150920423\n",
      "5.639465280634212\n",
      "5.633968726214064\n",
      "5.628474493330749\n",
      "5.622982587677778\n",
      "5.617493014971441\n",
      "5.612005780950894\n",
      "5.606520891378209\n",
      "5.601038352038441\n",
      "5.595558168739669\n",
      "5.590080347313091\n",
      "5.584604893613047\n",
      "5.5791318135171055\n",
      "5.573661112926108\n",
      "5.568192797764229\n",
      "5.562726873979031\n",
      "5.557263347541531\n",
      "5.551802224446244\n",
      "5.546343510711242\n",
      "5.540887212378219\n",
      "5.535433335512523\n",
      "5.529981886203231\n",
      "5.524532870563188\n",
      "5.519086294729067\n",
      "5.513642164861408\n",
      "5.508200487144685\n",
      "5.502761267787338\n",
      "5.497324513021833\n",
      "5.491890229104705\n",
      "5.486458422316606\n",
      "5.481029098962352\n",
      "5.475602265370959\n",
      "5.470177927895708\n",
      "5.46475609291416\n",
      "5.459336766828222\n",
      "5.453919956064175\n",
      "5.448505667072719\n",
      "5.443093906329011\n",
      "5.437684680332702\n",
      "5.43227799560798\n",
      "5.4268738587035985\n",
      "5.421472276192911\n",
      "5.416073254673911\n",
      "5.410676800769269\n",
      "5.405282921126346\n",
      "5.39989162241724\n",
      "5.394502911338811\n",
      "5.389116794612707\n",
      "5.383733278985395\n",
      "5.378352371228179\n",
      "5.372974078137236\n",
      "5.367598406533623\n",
      "5.362225363263312\n",
      "5.3568549551972096\n",
      "5.351487189231169\n",
      "5.346122072286011\n",
      "5.340759611307541\n",
      "5.335399813266567\n",
      "5.330042685158902\n",
      "5.324688234005392\n",
      "5.319336466851912\n",
      "5.313987390769385\n",
      "5.3086410128537835\n",
      "5.303297340226138\n",
      "5.297956380032538\n",
      "5.292618139444145\n",
      "5.287282625657183\n",
      "5.28194984589294\n",
      "5.27661980739777\n",
      "5.271292517443089\n",
      "5.2659679833253605\n",
      "5.2606462123661055\n",
      "5.25532721191188\n",
      "5.250010989334267\n",
      "5.244697552029864\n",
      "5.239386907420278\n",
      "5.234079062952097\n",
      "5.22877402609688\n",
      "5.223471804351131\n",
      "5.2181724052362854\n",
      "5.212875836298682\n",
      "5.207582105109539\n",
      "5.202291219264924\n",
      "5.197003186385733\n",
      "5.191718014117644\n",
      "5.186435710131102\n",
      "5.181156282121269\n",
      "5.175879737808\n",
      "5.170606084935788\n",
      "5.16533533127374\n",
      "5.1600674846155155\n",
      "5.154802552779297\n",
      "5.149540543607731\n",
      "5.144281464967888\n",
      "5.139025324751196\n",
      "5.133772130873402\n",
      "5.128521891274507\n",
      "5.1232746139187055\n",
      "5.118030306794327\n",
      "5.112788977913778\n",
      "5.107550635313463\n",
      "5.102315287053734\n",
      "5.097082941218798\n",
      "5.091853605916668\n",
      "5.086627289279072\n",
      "5.081403999461374\n",
      "5.0761837446425115\n",
      "5.070966533024888\n",
      "5.065752372834309\n",
      "5.060541272319884\n",
      "5.0553332397539394\n",
      "5.050128283431926\n",
      "5.044926411672317\n",
      "5.0397276328165255\n",
      "5.034531955228787\n",
      "5.029339387296074\n",
      "5.02414993742797\n",
      "5.018963614056578\n",
      "5.013780425636406\n",
      "5.008600380644246\n",
      "5.0034234875790675\n",
      "4.9982497549618925\n",
      "4.993079191335673\n",
      "4.987911805265171\n",
      "4.982747605336836\n",
      "4.977586600158653\n",
      "4.972428798360041\n",
      "4.967274208591689\n",
      "4.962122839525439\n",
      "4.9569746998541335\n",
      "4.951829798291467\n",
      "4.946688143571854\n",
      "4.941549744450266\n",
      "4.9364146097020845\n",
      "4.931282748122947\n",
      "4.926154168528579\n",
      "4.921028879754645\n",
      "4.915906890656575\n",
      "4.910788210109404\n",
      "4.905672847007588\n",
      "4.900560810264852\n",
      "4.895452108813992\n",
      "4.890346751606711\n",
      "4.885244747613428\n",
      "4.880146105823095\n",
      "4.875050835243008\n",
      "4.869958944898619\n",
      "4.864870443833334\n",
      "4.859785341108323\n",
      "4.854703645802311\n",
      "4.849625367011386\n",
      "4.844550513848776\n",
      "4.839479095444656\n",
      "4.834411120945918\n",
      "4.829346599515971\n",
      "4.824285540334508\n",
      "4.819227952597292\n",
      "4.814173845515924\n",
      "4.809123228317623\n",
      "4.804076110244982\n",
      "4.7990325005557475\n",
      "4.793992408522565\n",
      "4.788955843432752\n",
      "4.783922814588044\n",
      "4.77889333130435\n",
      "4.773867402911507\n",
      "4.768845038753011\n",
      "4.76382624818578\n",
      "4.75881104057988\n",
      "4.7537994253182605\n",
      "4.748791411796501\n",
      "4.743787009422525\n",
      "4.73878622761634\n",
      "4.733789075809755\n",
      "4.728795563446101\n",
      "4.723805699979958\n",
      "4.718819494876853\n",
      "4.713836957612988\n",
      "4.708858097674936\n",
      "4.703882924559357\n",
      "4.698911447772693\n",
      "4.693943676830869\n",
      "4.688979621258987\n",
      "4.684019290591026\n",
      "4.679062694369523\n",
      "4.674109842145266\n",
      "4.669160743476978\n",
      "4.664215407930993\n",
      "4.6592738450809374\n",
      "4.6543360645074054\n",
      "4.649402075797628\n",
      "4.644471888545144\n",
      "4.639545512349467\n",
      "4.634622956815747\n",
      "4.629704231554426\n",
      "4.624789346180907\n",
      "4.619878310315193\n",
      "4.614971133581553\n",
      "4.6100678256081595\n",
      "4.60516839602674\n",
      "4.600272854472219\n",
      "4.595381210582359\n",
      "4.590493473997395\n",
      "4.585609654359667\n",
      "4.580729761313264\n",
      "4.575853804503638\n",
      "4.57098179357724\n",
      "4.566113738181142\n",
      "4.56124964796266\n",
      "4.55638953256896\n",
      "4.551533401646698\n",
      "4.546681264841611\n",
      "4.541833131798142\n",
      "4.536989012159041\n",
      "4.5321489155649735\n",
      "4.527312851654126\n",
      "4.522480830061808\n",
      "4.5176528604200445\n",
      "4.512828952357179\n",
      "4.508009115497468\n",
      "4.503193359460669\n",
      "4.498381693861631\n",
      "4.493574128309887\n",
      "4.488770672409235\n",
      "4.483971335757321\n",
      "4.479176127945224\n",
      "4.474385058557034\n",
      "4.469598137169426\n",
      "4.4648153733512395\n",
      "4.46003677666305\n",
      "4.45526235665674\n",
      "4.450492122875076\n",
      "4.445726084851261\n",
      "4.4409642521085155\n",
      "4.436206634159636\n",
      "4.431453240506557\n",
      "4.426704080639911\n",
      "4.4219591640386\n",
      "4.417218500169331\n",
      "4.412482098486192\n",
      "4.407749968430206\n",
      "4.403022119428868\n",
      "4.398298560895718\n",
      "4.393579302229881\n",
      "4.388864352815618\n",
      "4.384153722021876\n",
      "4.379447419201834\n",
      "4.374745453692454\n",
      "4.370047834814021\n",
      "4.365354571869689\n",
      "4.360665674145024\n",
      "4.355981150907555\n",
      "4.351301011406297\n",
      "4.346625264871313\n",
      "4.341953920513238\n",
      "4.337286987522832\n",
      "4.332624475070507\n",
      "4.327966392305874\n",
      "4.323312748357274\n",
      "4.318663552331324\n",
      "4.314018813312444\n",
      "4.309378540362403\n",
      "4.304742742519852\n",
      "4.300111428799856\n",
      "4.295484608193437\n",
      "4.290862289667109\n",
      "4.286244482162407\n",
      "4.28163119459543\n",
      "4.277022435856378\n",
      "4.272418214809082\n",
      "4.267818540290548\n",
      "4.263223421110485\n",
      "4.25863286605085\n",
      "4.254046883865378\n",
      "4.249465483279131\n",
      "4.244888672988024\n",
      "4.240316461658371\n",
      "4.2357488579264215\n",
      "4.231185870397907\n",
      "4.226627507647572\n",
      "4.222073778218721\n",
      "4.21752469062277\n",
      "4.21298025333877\n",
      "4.208440474812971\n",
      "4.203905363458358\n",
      "4.1993749276542\n",
      "4.1948491757456\n",
      "4.190328116043039\n",
      "4.185811756821933\n",
      "4.181300106322182\n",
      "4.1767931727477245\n",
      "4.172290964266089\n",
      "4.167793489007956\n",
      "4.163300755066715\n",
      "4.158812770498025\n",
      "4.154329543319363\n",
      "4.149851081509618\n",
      "4.14537739300862\n",
      "4.140908485716736\n",
      "4.1364443674944225\n",
      "4.131985046161808\n",
      "4.127530529498256\n",
      "4.123080825241953\n",
      "4.118635941089472\n",
      "4.114195884695372\n",
      "4.109760663671757\n",
      "4.105330285587883\n",
      "4.100904757969734\n",
      "4.096484088299616\n",
      "4.092068284015748\n",
      "4.087657352511861\n",
      "4.083251301136788\n",
      "4.07885013719408\n",
      "4.074453867941597\n",
      "4.070062500591118\n",
      "4.065676042307955\n",
      "4.061294500210564\n",
      "4.056917881370153\n",
      "4.052546192810322\n",
      "4.048179441506658\n",
      "4.043817634386385\n",
      "4.039460778327977\n",
      "4.0351088801607995\n",
      "4.030761946664739\n",
      "4.026419984569846\n",
      "4.022083000555976\n",
      "4.0177510012524404\n",
      "4.013423993237649\n",
      "4.009101983038769\n",
      "4.004784977131378\n",
      "4.000472981939133\n",
      "3.996166003833428\n",
      "3.991864049133063\n",
      "3.987567124103919\n",
      "3.9832752349586396\n",
      "3.978988387856303\n",
      "3.974706588902112\n",
      "3.9704298441470764\n",
      "3.966158159587721\n",
      "3.9618915411657656\n",
      "3.957629994767835\n",
      "3.9533735262251657\n",
      "3.9491221413133144\n",
      "3.944875845751868\n",
      "3.940634645204169\n",
      "3.9363985452770387\n",
      "3.932167551520499\n",
      "3.9279416694275064\n",
      "3.9237209044336936\n",
      "3.919505261917106\n",
      "3.915294747197949\n",
      "3.911089365538339\n",
      "3.9068891221420596\n",
      "3.9026940221543165\n",
      "3.898504070661509\n",
      "3.8943192726909963\n",
      "3.890139633210867\n",
      "3.8859651571297307\n",
      "3.8817958492964872\n",
      "3.8776317145001244\n",
      "3.8734727574695094\n",
      "3.8693189828731875\n",
      "3.865170395319185\n",
      "3.8610269993548183\n",
      "3.8568887994665064\n",
      "3.852755800079589\n",
      "3.848628005558153\n",
      "3.844505420204857\n",
      "3.8403880482607673\n",
      "3.8362758939051975\n",
      "3.8321689612555474\n",
      "3.828067254367157\n",
      "3.8239707772331553\n",
      "3.8198795337843285\n",
      "3.8157935278889723\n",
      "3.811712763352768\n",
      "3.807637243918657\n",
      "3.8035669732667174\n",
      "3.7995019550140543\n",
      "3.7954421927146815\n",
      "3.7913876898594236\n",
      "3.787338449875815\n",
      "3.7832944761279985\n",
      "3.779255771916647\n",
      "3.7752223404788734\n",
      "3.7711941849881536\n",
      "3.7671713085542433\n",
      "3.7631537142231273\n",
      "3.759141404976939\n",
      "3.7551343837339153\n",
      "3.7511326533483333\n",
      "3.747136216610468\n",
      "3.7431450762465484\n",
      "3.7391592349187195\n",
      "3.73517869522501\n",
      "3.7312034596993056\n",
      "3.727233530811325\n",
      "3.723268910966606\n",
      "3.7193096025064882\n",
      "3.715355607708114\n",
      "3.711406928784418\n",
      "3.707463567884138\n",
      "3.7035255270918146\n",
      "3.699592808427814\n",
      "3.695665413848339\n",
      "3.691743345245456\n",
      "3.687826604447124\n",
      "3.683915193217222\n",
      "3.680009113255592\n",
      "3.676108366198085\n",
      "3.6722129536165986\n",
      "3.6683228770191385\n",
      "3.6644381378498756\n",
      "3.6605587374892026\n",
      "3.656684677253807\n",
      "3.65281595839674\n",
      "3.648952582107493\n",
      "3.645094549512077\n",
      "3.641241861673118\n",
      "3.6373945195899346\n",
      "3.633552524198642\n",
      "3.6297158763722472\n",
      "3.625884576920757\n",
      "3.622058626591283\n",
      "3.618238026068159\n",
      "3.6144227759730536\n",
      "3.610612876865096\n",
      "3.606808329241004\n",
      "3.603009133535211\n",
      "3.599215290120002\n",
      "3.5954267993056526\n",
      "3.591643661340578\n",
      "3.5878658764114726\n",
      "3.5840934446434676\n",
      "3.5803263661002824\n",
      "3.5765646407843925\n",
      "3.572808268637188\n",
      "3.5690572495391373\n",
      "3.5653115833099682\n",
      "3.5615712697088413\n",
      "3.557836308434529\n",
      "3.5541066991255956\n",
      "3.550382441360592\n",
      "3.5466635346582396\n",
      "3.5429499784776297\n",
      "3.5392417722184235\n",
      "3.53553891522105\n",
      "3.5318414067669117\n",
      "3.528149246078597\n",
      "3.524462432320094\n",
      "3.520780964597\n",
      "3.517104841956748\n",
      "3.5134340633888246\n",
      "3.5097686278249998\n",
      "3.5061085341395537\n",
      "3.502453781149511\n",
      "3.498804367614875\n",
      "3.495160292238863\n",
      "3.491521553668162\n",
      "3.4878881504931534\n",
      "3.484260081248177\n",
      "3.480637344411773\n",
      "3.47701993840694\n",
      "3.473407861601388\n",
      "3.4698011123077994\n",
      "3.4661996887840893\n",
      "3.4626035892336753\n",
      "3.4590128118057333\n",
      "3.455427354595477\n",
      "3.4518472156444298\n",
      "3.4482723929406944\n",
      "3.4447028844192302\n",
      "3.441138687962136\n",
      "3.437579801398931\n",
      "3.4340262225068385\n",
      "3.4304779490110655\n",
      "3.426934978585105\n",
      "3.4233973088510132\n",
      "3.419864937379708\n",
      "3.4163378616912614\n",
      "3.4128160792552027\n",
      "3.409299587490802\n",
      "3.4057883837673906\n",
      "3.4022824654046446\n",
      "3.398781829672897\n",
      "3.39528647379345\n",
      "3.391796394938865\n",
      "3.3883115902332896\n",
      "3.3848320567527566\n",
      "3.3813577915255\n",
      "3.377888791532268\n",
      "3.3744250537066396\n",
      "3.3709665749353395\n",
      "3.3675133520585496\n",
      "3.3640653818702426\n",
      "3.3606226611184904\n",
      "3.3571851865057876\n",
      "3.3537529546893747\n",
      "3.3503259622815698\n",
      "3.346904205850075\n"
     ]
    }
   ],
   "source": [
    "w_hat, loss = logistic_fit(X, y, 0.0001, 6, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7a9168f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5682915 , 0.0983783 , 0.77498696, 0.68009828, 0.3274488 ,\n",
       "        0.33870002],\n",
       "       [0.76013215, 0.43268594, 0.05480006, 0.7004445 , 0.14413017,\n",
       "        0.77499973],\n",
       "       [0.04878778, 0.83140659, 0.54388055, 0.45037612, 0.95784219,\n",
       "        0.30571494],\n",
       "       [0.52959964, 0.27441546, 0.91979746, 0.13487666, 0.25600735,\n",
       "        0.27896867],\n",
       "       [0.34435716, 0.61280325, 0.8053516 , 0.51750511, 0.10733246,\n",
       "        0.83776394]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01d88450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.598277278632956,\n",
       " 3.5961149640492924,\n",
       " 3.5939591173494456,\n",
       " 3.5918097105510753,\n",
       " 3.5896667157369238,\n",
       " 3.587530105055761,\n",
       " 3.5853998507233213,\n",
       " 3.583275925023202,\n",
       " 3.5811583003077736,\n",
       " 3.5790469489990424,\n",
       " 3.5769418435895215,\n",
       " 3.574842956643058,\n",
       " 3.572750260795664,\n",
       " 3.570663728756324,\n",
       " 3.5685833333077723,\n",
       " 3.5665090473072767,\n",
       " 3.564440843687381,\n",
       " 3.56237869545665,\n",
       " 3.560322575700384,\n",
       " 3.5582724575813214,\n",
       " 3.5562283143403293,\n",
       " 3.554190119297067,\n",
       " 3.5521578458506453,\n",
       " 3.5501314674802575,\n",
       " 3.5481109577458034,\n",
       " 3.5460962902884963,\n",
       " 3.5440874388314447,\n",
       " 3.5420843771802333,\n",
       " 3.540087079223475,\n",
       " 3.5380955189333556,\n",
       " 3.536109670366161,\n",
       " 3.534129507662786,\n",
       " 3.5321550050492334,\n",
       " 3.5301861368370973,\n",
       " 3.528222877424023,\n",
       " 3.526265201294171,\n",
       " 3.524313083018644,\n",
       " 3.522366497255916,\n",
       " 3.5204254187522417,\n",
       " 3.5184898223420533,\n",
       " 3.5165596829483374,\n",
       " 3.514634975583012,\n",
       " 3.512715675347272,\n",
       " 3.5108017574319352,\n",
       " 3.508893197117775,\n",
       " 3.506989969775825,\n",
       " 3.5050920508676895,\n",
       " 3.5031994159458315,\n",
       " 3.501312040653849,\n",
       " 3.499429900726742,\n",
       " 3.4975529719911567,\n",
       " 3.4956812303656393,\n",
       " 3.493814651860852,\n",
       " 3.491953212579798,\n",
       " 3.49009688871802,\n",
       " 3.4882456565637994,\n",
       " 3.4863994924983346,\n",
       " 3.484558372995913,\n",
       " 3.4827222746240722,\n",
       " 3.4808911740437494,\n",
       " 3.479065048009415,\n",
       " 3.4772438733692055,\n",
       " 3.475427627065043,\n",
       " 3.473616286132733,\n",
       " 3.471809827702073,\n",
       " 3.4700082289969316,\n",
       " 3.4682114673353275,\n",
       " 3.4664195201294987,\n",
       " 3.4646323648859614,\n",
       " 3.4628499792055565,\n",
       " 3.4610723407834905,\n",
       " 3.4592994274093662,\n",
       " 3.4575312169672023,\n",
       " 3.4557676874354506,\n",
       " 3.4540088168869953,\n",
       " 3.4522545834891534,\n",
       " 3.4505049655036593,\n",
       " 3.4487599412866405,\n",
       " 3.4470194892885986,\n",
       " 3.4452835880543646,\n",
       " 3.443552216223056,\n",
       " 3.4418253525280242,\n",
       " 3.440102975796799,\n",
       " 3.4383850649510106,\n",
       " 3.4366715990063326,\n",
       " 3.4349625570723816,\n",
       " 3.4332579183526426,\n",
       " 3.431557662144369,\n",
       " 3.4298617678384766,\n",
       " 3.42817021491944,\n",
       " 3.426482982965179,\n",
       " 3.4248000516469275,\n",
       " 3.423121400729116,\n",
       " 3.4214470100692362,\n",
       " 3.4197768596176936,\n",
       " 3.418110929417671,\n",
       " 3.4164491996049713,\n",
       " 3.4147916504078624,\n",
       " 3.4131382621469144,\n",
       " 3.4114890152348316,\n",
       " 3.409843890176281,\n",
       " 3.408202867567707,\n",
       " 3.4065659280971587,\n",
       " 3.4049330525440937,\n",
       " 3.403304221779187,\n",
       " 3.401679416764131,\n",
       " 3.4000586185514368,\n",
       " 3.3984418082842254,\n",
       " 3.396828967196015,\n",
       " 3.3952200766105043,\n",
       " 3.3936151179413585,\n",
       " 3.392014072691977,\n",
       " 3.3904169224552696,\n",
       " 3.3888236489134242,\n",
       " 3.3872342338376717,\n",
       " 3.385648659088044,\n",
       " 3.384066906613132,\n",
       " 3.3824889584498408,\n",
       " 3.3809147967231357,\n",
       " 3.3793444036457907,\n",
       " 3.377777761518132,\n",
       " 3.3762148527277795,\n",
       " 3.3746556597493806,\n",
       " 3.373100165144345,\n",
       " 3.3715483515605786,\n",
       " 3.3700002017322066,\n",
       " 3.3684556984793055,\n",
       " 3.366914824707621,\n",
       " 3.36537756340829,\n",
       " 3.3638438976575586,\n",
       " 3.3623138106164974,\n",
       " 3.3607872855307144,\n",
       " 3.359264305730065,\n",
       " 3.357744854628361,\n",
       " 3.3562289157230776,\n",
       " 3.3547164725950602,\n",
       " 3.353207508908221,\n",
       " 3.3517020084092444,\n",
       " 3.3501999549272825,\n",
       " 3.3487013323736576,\n",
       " 3.3472061247415463,\n",
       " 3.3457143161056866,\n",
       " 3.3442258906220608,\n",
       " 3.342740832527588,\n",
       " 3.3412591261398163,\n",
       " 3.3397807558566055,\n",
       " 3.338305706155815,\n",
       " 3.3368339615949947,\n",
       " 3.3353655068110597,\n",
       " 3.3339003265199767,\n",
       " 3.33243840551645,\n",
       " 3.330979728673594,\n",
       " 3.32952428094262,\n",
       " 3.3280720473525123,\n",
       " 3.326623013009702,\n",
       " 3.3251771630977522,\n",
       " 3.3237344828770277,\n",
       " 3.3222949576843703,\n",
       " 3.3208585729327798,\n",
       " 3.319425314111081,\n",
       " 3.317995166783603,\n",
       " 3.316568116589847,\n",
       " 3.315144149244165,\n",
       " 3.313723250535425,\n",
       " 3.3123054063266903,\n",
       " 3.310890602554883,\n",
       " 3.3094788252304634,\n",
       " 3.308070060437093,\n",
       " 3.3066642943313105,\n",
       " 3.305261513142199,\n",
       " 3.303861703171062,\n",
       " 3.302464850791083,\n",
       " 3.301070942447007,\n",
       " 3.2996799646548016,\n",
       " 3.2982919040013337,\n",
       " 3.2969067471440354,\n",
       " 3.295524480810576,\n",
       " 3.2941450917985318,\n",
       " 3.292768566975056,\n",
       " 3.29139489327655,\n",
       " 3.2900240577083366,\n",
       " 3.2886560473443236,\n",
       " 3.287290849326683,\n",
       " 3.285928450865518,\n",
       " 3.284568839238537,\n",
       " 3.283212001790726,\n",
       " 3.2818579259340184,\n",
       " 3.2805065991469715,\n",
       " 3.279158008974439,\n",
       " 3.277812143027244,\n",
       " 3.2764689889818506,\n",
       " 3.2751285345800465,\n",
       " 3.2737907676286127,\n",
       " 3.272455675998998,\n",
       " 3.271123247627004,\n",
       " 3.2697934705124525,\n",
       " 3.268466332718866,\n",
       " 3.2671418223731514,\n",
       " 3.2658199276652753,\n",
       " 3.2645006368479415,\n",
       " 3.2631839382362755,\n",
       " 3.261869820207504,\n",
       " 3.2605582712006367,\n",
       " 3.259249279716149,\n",
       " 3.257942834315669,\n",
       " 3.2566389236216557,\n",
       " 3.2553375363170876,\n",
       " 3.2540386611451506,\n",
       " 3.2527422869089224,\n",
       " 3.2514484024710577,\n",
       " 3.250156996753486,\n",
       " 3.2488680587370866,\n",
       " 3.2475815774613945,\n",
       " 3.24629754202428,\n",
       " 3.2450159415816486,\n",
       " 3.243736765347128,\n",
       " 3.24246000259177,\n",
       " 3.2411856426437367,\n",
       " 3.2399136748880024,\n",
       " 3.2386440887660513,\n",
       " 3.237376873775572,\n",
       " 3.236112019470159,\n",
       " 3.2348495154590147,\n",
       " 3.233589351406644,\n",
       " 3.232331517032567,\n",
       " 3.2310760021110116,\n",
       " 3.229822796470625,\n",
       " 3.228571889994177,\n",
       " 3.227323272618269,\n",
       " 3.2260769343330353,\n",
       " 3.2248328651818614,\n",
       " 3.223591055261083,\n",
       " 3.2223514947197103,\n",
       " 3.221114173759125,\n",
       " 3.2198790826328083,\n",
       " 3.218646211646044,\n",
       " 3.2174155511556415,\n",
       " 3.2161870915696475,\n",
       " 3.2149608233470683,\n",
       " 3.213736736997587,\n",
       " 3.212514823081282,\n",
       " 3.211295072208351,\n",
       " 3.2100774750388354,\n",
       " 3.2088620222823345,\n",
       " 3.207648704697746,\n",
       " 3.2064375130929803,\n",
       " 3.2052284383246885,\n",
       " 3.2040214712979966,\n",
       " 3.2028166029662324,\n",
       " 3.201613824330659,\n",
       " 3.200413126440198,\n",
       " 3.1992145003911765,\n",
       " 3.1980179373270516,\n",
       " 3.1968234284381474,\n",
       " 3.195630964961399,\n",
       " 3.1944405381800824,\n",
       " 3.193252139423558,\n",
       " 3.192065760067011,\n",
       " 3.1908813915311924,\n",
       " 3.1896990252821666,\n",
       " 3.188518652831044,\n",
       " 3.187340265733745,\n",
       " 3.1861638555907277,\n",
       " 3.184989414046749,\n",
       " 3.1838169327906107,\n",
       " 3.182646403554905,\n",
       " 3.181477818115774,\n",
       " 3.1803111682926564,\n",
       " 3.1791464459480454,\n",
       " 3.1779836429872432,\n",
       " 3.176822751358116,\n",
       " 3.1756637630508546,\n",
       " 3.1745066700977316,\n",
       " 3.173351464572864,\n",
       " 3.1721981385919675,\n",
       " 3.1710466843121328,\n",
       " 3.1698970939315756,\n",
       " 3.1687493596894085,\n",
       " 3.1676034738654075,\n",
       " 3.1664594287797816,\n",
       " 3.165317216792934,\n",
       " 3.1641768303052396,\n",
       " 3.163038261756814,\n",
       " 3.161901503627284,\n",
       " 3.1607665484355643,\n",
       " 3.1596333887396284,\n",
       " 3.1585020171362927,\n",
       " 3.157372426260982,\n",
       " 3.156244608787518,\n",
       " 3.155118557427894,\n",
       " 3.1539942649320576,\n",
       " 3.152871724087691,\n",
       " 3.151750927719997,\n",
       " 3.1506318686914803,\n",
       " 3.1495145399017344,\n",
       " 3.1483989342872296,\n",
       " 3.1472850448210985,\n",
       " 3.1461728645129283,\n",
       " 3.145062386408546,\n",
       " 3.1439536035898157,\n",
       " 3.1428465091744258,\n",
       " 3.141741096315689,\n",
       " 3.14063735820233,\n",
       " 3.1395352880582847,\n",
       " 3.1384348791425025,\n",
       " 3.137336124748734,\n",
       " 3.1362390182053406,\n",
       " 3.1351435528750877,\n",
       " 3.1340497221549515,\n",
       " 3.132957519475917,\n",
       " 3.131866938302789,\n",
       " 3.1307779721339877,\n",
       " 3.129690614501365,\n",
       " 3.128604858970005,\n",
       " 3.1275206991380315,\n",
       " 3.126438128636423,\n",
       " 3.125357141128822,\n",
       " 3.1242777303113427,\n",
       " 3.123199889912385,\n",
       " 3.122123613692454,\n",
       " 3.121048895443966,\n",
       " 3.1199757289910726,\n",
       " 3.118904108189472,\n",
       " 3.117834026926232,\n",
       " 3.1167654791196036,\n",
       " 3.115698458718844,\n",
       " 3.1146329597040414,\n",
       " 3.113568976085933,\n",
       " 3.1125065019057288,\n",
       " 3.1114455312349354,\n",
       " 3.110386058175187,\n",
       " 3.1093280768580627,\n",
       " 3.1082715814449258,\n",
       " 3.1072165661267364,\n",
       " 3.1061630251239016,\n",
       " 3.105110952686085,\n",
       " 3.1040603430920535,\n",
       " 3.1030111906495015,\n",
       " 3.10196348969489,\n",
       " 3.1009172345932776,\n",
       " 3.099872419738157,\n",
       " 3.0988290395512905,\n",
       " 3.0977870884825527,\n",
       " 3.096746561009759,\n",
       " 3.095707451638516,\n",
       " 3.0946697549020556,\n",
       " 3.0936334653610786,\n",
       " 3.0925985776035936,\n",
       " 3.0915650862447657,\n",
       " 3.090532985926758,\n",
       " 3.089502271318576,\n",
       " 3.0884729371159145,\n",
       " 3.0874449780410047,\n",
       " 3.086418388842463,\n",
       " 3.085393164295139,\n",
       " 3.0843692991999667,\n",
       " 3.0833467883838104,\n",
       " 3.0823256266993244,\n",
       " 3.0813058090247982,\n",
       " 3.080287330264015,\n",
       " 3.079270185346101,\n",
       " 3.078254369225388,\n",
       " 3.077239876881261,\n",
       " 3.076226703318022,\n",
       " 3.075214843564742,\n",
       " 3.074204292675128,\n",
       " 3.0731950457273727,\n",
       " 3.0721870978240227,\n",
       " 3.0711804440918358,\n",
       " 3.070175079681644,\n",
       " 3.069170999768218,\n",
       " 3.068168199550128,\n",
       " 3.0671666742496133,\n",
       " 3.0661664191124416,\n",
       " 3.0651674294077806,\n",
       " 3.0641697004280615,\n",
       " 3.0631732274888503,\n",
       " 3.0621780059287147,\n",
       " 3.0611840311090925,\n",
       " 3.0601912984141655,\n",
       " 3.0591998032507273,\n",
       " 3.0582095410480563,\n",
       " 3.0572205072577923,\n",
       " 3.056232697353803,\n",
       " 3.0552461068320635,\n",
       " 3.0542607312105297,\n",
       " 3.053276566029016,\n",
       " 3.052293606849068,\n",
       " 3.0513118492538474,\n",
       " 3.0503312888479996,\n",
       " 3.0493519212575424,\n",
       " 3.048373742129739,\n",
       " 3.047396747132986,\n",
       " 3.046420931956684,\n",
       " 3.0454462923111287,\n",
       " 3.044472823927393,\n",
       " 3.0435005225572005,\n",
       " 3.0425293839728234,\n",
       " 3.0415594039669576,\n",
       " 3.0405905783526137,\n",
       " 3.039622902963,\n",
       " 3.03865637365141,\n",
       " 3.037690986291112,\n",
       " 3.0367267367752326,\n",
       " 3.0357636210166574,\n",
       " 3.034801634947904,\n",
       " 3.0338407745210247,\n",
       " 3.032881035707496,\n",
       " 3.031922414498107,\n",
       " 3.030964906902854,\n",
       " 3.030008508950831,\n",
       " 3.0290532166901283,\n",
       " 3.0280990261877236,\n",
       " 3.027145933529379,\n",
       " 3.0261939348195326,\n",
       " 3.0252430261812004,\n",
       " 3.0242932037558723,\n",
       " 3.0233444637034066,\n",
       " 3.02239680220193,\n",
       " 3.0214502154477394,\n",
       " 3.020504699655197,\n",
       " 3.019560251056634,\n",
       " 3.0186168659022496,\n",
       " 3.0176745404600136,\n",
       " 3.016733271015567,\n",
       " 3.015793053872127,\n",
       " 3.014853885350389,\n",
       " 3.0139157617884287,\n",
       " 3.012978679541611,\n",
       " 3.0120426349824903,\n",
       " 3.0111076245007227,\n",
       " 3.0101736445029643,\n",
       " 3.0092406914127827,\n",
       " 3.0083087616705644,\n",
       " 3.007377851733422,\n",
       " 3.0064479580751033,\n",
       " 3.0055190771859004,\n",
       " 3.0045912055725577,\n",
       " 3.003664339758186,\n",
       " 3.0027384762821696,\n",
       " 3.0018136117000798,\n",
       " 3.000889742583585,\n",
       " 2.9999668655203684,\n",
       " 2.999044977114032,\n",
       " 2.9981240739840196,\n",
       " 2.997204152765524,\n",
       " 2.9962852101094053,\n",
       " 2.995367242682107,\n",
       " 2.9944502471655685,\n",
       " 2.9935342202571413,\n",
       " 2.9926191586695103,\n",
       " 2.9917050591306054,\n",
       " 2.9907919183835237,\n",
       " 2.9898797331864464,\n",
       " 2.9889685003125557,\n",
       " 2.9880582165499567,\n",
       " 2.987148878701596,\n",
       " 2.9862404835851835,\n",
       " 2.9853330280331103,\n",
       " 2.9844265088923727,\n",
       " 2.983520923024493,\n",
       " 2.9826162673054406,\n",
       " 2.9817125386255587,\n",
       " 2.9808097338894814,\n",
       " 2.979907850016063,\n",
       " 2.9790068839383,\n",
       " 2.978106832603253,\n",
       " 2.977207692971979,\n",
       " 2.9763094620194495,\n",
       " 2.9754121367344784,\n",
       " 2.974515714119653,\n",
       " 2.9736201911912556,\n",
       " 2.972725564979194,\n",
       " 2.971831832526925,\n",
       " 2.970938990891391,\n",
       " 2.970047037142939,\n",
       " 2.9691559683652584,\n",
       " 2.9682657816553024,\n",
       " 2.9673764741232245,\n",
       " 2.966488042892308,\n",
       " 2.965600485098893,\n",
       " 2.9647137978923106,\n",
       " 2.9638279784348156,\n",
       " 2.9629430239015178,\n",
       " 2.9620589314803127,\n",
       " 2.9611756983718167,\n",
       " 2.9602933217892997,\n",
       " 2.959411798958616,\n",
       " 2.9585311271181483,\n",
       " 2.9576513035187286,\n",
       " 2.956772325423584,\n",
       " 2.9558941901082663,\n",
       " 2.9550168948605915,\n",
       " 2.954140436980571,\n",
       " 2.9532648137803554,\n",
       " 2.9523900225841646,\n",
       " 2.951516060728228,\n",
       " 2.9506429255607247,\n",
       " 2.9497706144417175,\n",
       " 2.948899124743091]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "676d7726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.63393137  6.94243177  8.20755757  6.31205733  3.94556431  8.17835926]\n",
      " [10.98559778 11.74849924 10.29951822 14.50510427 11.03193427 12.29068121]\n",
      " [ 8.14081206  9.11898319 11.35880847  9.18597541  7.69410481  9.27384021]\n",
      " [ 5.29806008  4.41808075  8.46557935  5.31147261  5.35148135  4.16281933]\n",
      " [ 9.84218882  9.07936978 12.16044554 11.72409041  7.45805694 11.03905166]\n",
      " [13.74676559  8.03331811 12.04371848 12.99411727  4.71522356 13.47412817]]\n",
      "[[7.89667146e-02 1.07503867e-01 3.80944092e-01 5.72342437e-02\n",
      "  5.36909502e-03 3.69981987e-01]\n",
      " [2.37241063e-02 5.08760937e-02 1.19461867e-02 8.01109921e-01\n",
      "  2.48492650e-02 8.74944274e-02]\n",
      " [2.83879201e-02 7.55001644e-02 7.09074158e-01 8.07313563e-02\n",
      "  1.81606371e-02 8.81457641e-02]\n",
      " [3.62936746e-02 1.50543072e-02 8.61920242e-01 3.67837437e-02\n",
      "  3.82852511e-02 1.16627816e-02]\n",
      " [4.63130935e-02 2.15981071e-02 4.70446121e-01 3.04090791e-01\n",
      "  4.26862963e-03 1.53283257e-01]\n",
      " [4.13559014e-01 1.36527072e-03 7.53205579e-02 1.94834777e-01\n",
      "  4.94525426e-05 3.14870928e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 2, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X, w_hat)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    return np.sum(y == y_hat)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a29d892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66f95c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22f4b7daa00>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(500), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae9a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f7233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51755ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b8568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1da1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2bf5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507442ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69bde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b73d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a0c35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba6cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d853a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f63e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e659d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7df7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd148fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18545074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0380e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84a215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1e6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5d264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4fb65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b1639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "56026607",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.special import softmax\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "def loss(X, Y, W):\n",
    "    \"\"\"\n",
    "    Y: onehot encoded\n",
    "    \"\"\"\n",
    "    Z = - X @ W\n",
    "    N = X.shape[0]\n",
    "    loss = 1/N * (np.trace(X @ W @ Y.T) + np.sum(np.log(np.sum(np.exp(Z), axis=1))))\n",
    "    return loss\n",
    "\n",
    "def gradient(X, Y, W, mu):\n",
    "    \"\"\"\n",
    "    Y: onehot encoded \n",
    "    \"\"\"\n",
    "    Z = - X @ W\n",
    "    P = softmax(Z, axis=1)\n",
    "    N = X.shape[0]\n",
    "    gd = 1/N * (X.T @ (Y - P)) + 2 * mu * W\n",
    "    return gd\n",
    "\n",
    "def gradient_descent(X, Y, max_iter=1000, eta=0.1, mu=0.01):\n",
    "    \"\"\"\n",
    "    Very basic gradient descent algorithm with fixed eta and mu\n",
    "    \"\"\"\n",
    "    Y_onehot = onehot_encoder.fit_transform(Y.reshape(-1,1))\n",
    "    W = np.zeros((X.shape[1], Y_onehot.shape[1]))\n",
    "    step = 0\n",
    "    step_lst = [] \n",
    "    loss_lst = []\n",
    "    W_lst = []\n",
    " \n",
    "    while step < max_iter:\n",
    "        step += 1\n",
    "        W -= eta * gradient(X, Y_onehot, W, mu)\n",
    "        step_lst.append(step)\n",
    "        W_lst.append(W)\n",
    "        loss_lst.append(loss(X, Y_onehot, W))\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'step': step_lst, \n",
    "        'loss': loss_lst\n",
    "    })\n",
    "    return df, W\n",
    "\n",
    "class Multiclass:\n",
    "    def fit(self, X, Y):\n",
    "        self.loss_steps, self.W = gradient_descent(X, Y)\n",
    "\n",
    "    def loss_plot(self):\n",
    "        return self.loss_steps.plot(\n",
    "            x='step', \n",
    "            y='loss',\n",
    "            xlabel='step',\n",
    "            ylabel='loss'\n",
    "        )\n",
    "\n",
    "    def predict(self, H):\n",
    "        Z = - H @ self.W\n",
    "        P = softmax(Z, axis=1)\n",
    "        return np.argmax(P, axis=1)\n",
    "    \n",
    "X = load_iris().data\n",
    "Y = load_iris().target\n",
    "\n",
    "# fit model\n",
    "model = Multiclass()\n",
    "model.fit(X, Y)\n",
    "\n",
    "# plot loss\n",
    "model.loss_plot()\n",
    "\n",
    "# predict \n",
    "model.predict(X)\n",
    "\n",
    "# check the predicted value and the actual value\n",
    "model.predict(X) == Y\n",
    "view rawmulticlass-logistic.py hosted with  by GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe7ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
